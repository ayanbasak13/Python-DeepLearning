{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "import collections\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "import sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi.', 'Hallo!'], ['Hi.', 'Grüß Gott!']]\n",
      "['Hi.\\tHallo!', 'Hi.\\tGrüß Gott!']\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "all_lines=[]\n",
    "\n",
    "fptr = open('deu.txt', 'r', encoding='utf-8')\n",
    "# read all text\n",
    "lines = fptr.readlines()\n",
    "#print(lines)\n",
    "for line in lines :\n",
    "    #print(line)\n",
    "    line=line.strip()\n",
    "    k = line.split('\\t')\n",
    "    \n",
    "    all_lines.append(line)\n",
    "    pairs.append(k)\n",
    "print(pairs[0:2])\n",
    "print(all_lines[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "cleaned = list()\n",
    "# prepare regex for char filtering\n",
    "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "# prepare translation table for removing punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for pair in pairs:\n",
    "    #print(pair[0])\n",
    "    \n",
    "        \n",
    "    clean_pair = list()\n",
    "    for line in pair:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        clean_pair.append(' '.join(line))\n",
    "    cleaned.append(clean_pair)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi => hallo\n",
      "hi => gru gott\n"
     ]
    }
   ],
   "source": [
    "print(cleaned[0][0] + \" => \" + cleaned[0][1])\n",
    "print(cleaned[1][0] + \" => \" + cleaned[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 'hallo'], ['hi', 'gru gott']]\n",
      "10000\n",
      "['hi', 'hallo']\n",
      "['hi', 'gru gott']\n"
     ]
    }
   ],
   "source": [
    "# reduce dataset size\n",
    "n_sentences = 10000\n",
    "dataset = cleaned[:n_sentences]\n",
    "print(dataset[0:2])\n",
    "print(len(dataset))\n",
    "print(dataset[0:2][0])\n",
    "print(dataset[0:2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'hallo']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    if(len(dataset[i][0]) > max_eng_length) :\n",
    "        max_eng_length = len(dataset[i][0])\n",
    "    if(len(dataset[i][1]) > max_ger_length) :\n",
    "        max_ger_length = len(dataset[i][1])\n",
    "        \n",
    "print(max_eng_length)\n",
    "print(max_ger_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "gru gott\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    questions.append(dataset[i][0])\n",
    "    labels.append(dataset[i][1])\n",
    "print(questions[1])\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(que, lab):\n",
    "    # Preprocess\n",
    "    qs = []\n",
    "    lb = []\n",
    "\n",
    "    # to the lower case\n",
    "    for i in que :\n",
    "        i=i.lower()\n",
    "        qs.append(i)\n",
    "    for j in lab :\n",
    "        j=j.lower()\n",
    "        lb.append(j)\n",
    "\n",
    "    # create lookup tables for English and French data\n",
    "    CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "    source_vocab = []\n",
    "    target_vocab = []\n",
    "    \n",
    "    for q in qs :\n",
    "        for j in q.split() :\n",
    "            source_vocab.append(j)\n",
    "            \n",
    "    source_vocab = set(source_vocab)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for l in lb :\n",
    "        for k in l.split() :\n",
    "            target_vocab.append(k)\n",
    "            \n",
    "    target_vocab = set(target_vocab)\n",
    "    #print(target_vocab)\n",
    "    \n",
    "    source_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(source_vocab, len(CODES)):\n",
    "        source_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    source_int_to_vocab = {v_i: v for v, v_i in source_vocab_to_int.items()}    \n",
    "    \n",
    "\n",
    " \n",
    "    target_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(target_vocab, len(CODES)):\n",
    "        target_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    target_int_to_vocab = {v_i: v for v, v_i in target_vocab_to_int.items()}\n",
    "    \n",
    "    \n",
    "\n",
    "    # create list of sentences whose words are represented in index\n",
    "    \n",
    "    source_text = []\n",
    "    target_text = []\n",
    "    \n",
    "    for q in qs :\n",
    "        source_tokens = q.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        source_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(source_tokens):\n",
    "            if (token != \"\"):\n",
    "                source_token_id.append(source_vocab_to_int[token])\n",
    "\n",
    "        source_text.append(source_token_id)        \n",
    "\n",
    "    for l in lb :\n",
    "        target_tokens = l.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        target_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(target_tokens):\n",
    "            if (token != \"\"):\n",
    "                target_token_id.append(target_vocab_to_int[token])\n",
    "       \n",
    "                \n",
    "        # put <EOS> token at the end of the chosen target sentence\n",
    "        # this token suggests when to stop creating a sequence\n",
    "        target_token_id.append(target_vocab_to_int['<EOS>'])        \n",
    "        \n",
    "        target_text.append(target_token_id) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (source_text, target_text),(source_vocab_to_int, target_vocab_to_int),(source_int_to_vocab, target_int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[845], [845]]\n",
      "[[3113, 1], [3454, 463, 1]]\n"
     ]
    }
   ],
   "source": [
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "\n",
    "print(source_int_text[0:2])\n",
    "print(target_int_text[0:2])\n",
    "#print(target_int_to_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_model_inputs():\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets') \n",
    "    \n",
    "    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n",
    "    max_target_len = tf.reduce_max(target_sequence_length)    \n",
    "    \n",
    "    return inputs, targets, target_sequence_length, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_inputs():\n",
    "    lr_rate = tf.placeholder(tf.float32, name='lr_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return lr_rate, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # get '<GO>' id\n",
    "    go_id = target_vocab_to_int['<GO>']\n",
    "    \n",
    "    after_slice = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    after_concat = tf.concat( [tf.fill([batch_size, 1], go_id), after_slice], 1)\n",
    "    \n",
    "    return after_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\n",
    "\n",
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n",
    "                   source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    :return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    embed = tf.contrib.layers.embed_sequence(rnn_inputs, \n",
    "                                             vocab_size=source_vocab_size, \n",
    "                                             embed_dim=encoding_embedding_size)\n",
    "    \n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(rnn_size), keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    '''((encoder_fw_outputs,\n",
    "              encoder_bw_outputs),\n",
    "             (encoder_fw_state,\n",
    "              encoder_bw_state)) = (\n",
    "                tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked_cells,\n",
    "                                                cell_bw=stacked_cells,\n",
    "                                                inputs = embed,\n",
    "                                                time_major=True,\n",
    "                                                dtype=tf.float32)\n",
    "                )'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    encoder_outputs_fw_bw, encoder_last_state_fw_bw = tf.nn.bidirectional_dynamic_rnn(\n",
    "    cell_fw=stacked_cells,\n",
    "    cell_bw=stacked_cells,\n",
    "    inputs=embed,\n",
    "    dtype=tf.float32,\n",
    "    time_major=False)\n",
    "    \n",
    "    encoder_outputs_fw, encoder_outputs_bw = encoder_outputs_fw_bw\n",
    "    encoder_outputs = tf.concat([encoder_outputs_fw, encoder_outputs_bw], 2)\n",
    "\n",
    "    encoder_last_state_fw, encoder_last_state_bw = encoder_last_state_fw_bw\n",
    "\n",
    "    encoder_last_state_zipped = zip(encoder_last_state_fw, encoder_last_state_bw)\n",
    "    encoder_last_state_list = [LSTMStateTuple(c=tf.concat([fw.c, bw.c], 1), h=tf.concat([fw.h, bw.h], 1))\n",
    "                               for fw, bw in encoder_last_state_zipped]\n",
    "    encoder_last_state = tuple(encoder_last_state_list)\n",
    "\n",
    "    \n",
    "    '''print(encoder_fw_outputs)\n",
    "    print(\"#############\")\n",
    "    print(encoder_fw_state)\n",
    "    print(\"#############\")\n",
    "    print(encoder_bw_state)\n",
    "    print(\"#############\")\n",
    "    #enc_state = tf.Variable([64,128])\n",
    "    #encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), axis = 1)\n",
    "    print(encoder_outputs)\n",
    "    print(\"#############\")\n",
    "    \n",
    "    #encoder_final_state_c = tf.concat((encoder_fw_state[0].c, encoder_bw_state[0].c), axis = 0)\n",
    "\n",
    "    #encoder_final_state_h = tf.concat((encoder_fw_state[0].h, encoder_bw_state[0].h), axis = 0)    \n",
    "    \n",
    "\n",
    "    print(encoder_final_state_c)\n",
    "    print(\"#############\")\n",
    "    \n",
    "    alternates_c = tf.map_fn(lambda x: (x, x), encoder_final_state_c, dtype=(tf.float32,tf.float32))\n",
    "    alternates_h = tf.map_fn(lambda x: (x, x), encoder_final_state_h, dtype=(tf.float32,tf.float32))  \n",
    "    encoder_final_state = LSTMStateTuple(c=encoder_final_state_c,h=encoder_final_state_h)\n",
    "    print(encoder_final_state)'''\n",
    "    \n",
    "    return encoder_outputs,encoder_last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                         target_sequence_length, max_summary_length, \n",
    "                         output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a training process in decoding layer \n",
    "    :return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    # for only input layer\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, \n",
    "                                               target_sequence_length)\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "\n",
    "    # unrolling the decoder layer\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_summary_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length,\n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a inference process in decoding layer \n",
    "    :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings, \n",
    "                                                      tf.fill([batch_size], start_of_sequence_id), \n",
    "                                                      end_of_sequence_id)\n",
    "    \n",
    "\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "    \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer(dec_input, encoder_state,\n",
    "                   target_sequence_length, max_target_sequence_length,\n",
    "                   rnn_size,\n",
    "                   num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    target_vocab_size = len(target_vocab_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "    \n",
    "    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(2*rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        output_layer = tf.layers.Dense(target_vocab_size)\n",
    "        train_output = decoding_layer_train(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embed_input, \n",
    "                                            target_sequence_length, \n",
    "                                            max_target_sequence_length, \n",
    "                                            output_layer, \n",
    "                                            keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        infer_output = decoding_layer_infer(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embeddings, \n",
    "                                            target_vocab_to_int['<GO>'], \n",
    "                                            target_vocab_to_int['<EOS>'], \n",
    "                                            max_target_sequence_length, \n",
    "                                            target_vocab_size, \n",
    "                                            output_layer,\n",
    "                                            batch_size,\n",
    "                                            keep_prob)\n",
    "\n",
    "    return (train_output, infer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  target_sequence_length,\n",
    "                  max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence model\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    enc_outputs, enc_states = encoding_layer(input_data, \n",
    "                                             rnn_size, \n",
    "                                             num_layers, \n",
    "                                             keep_prob, \n",
    "                                             source_vocab_size, \n",
    "                                             enc_embedding_size)\n",
    "    \n",
    "    dec_input = process_decoder_input(target_data, \n",
    "                                      target_vocab_to_int, \n",
    "                                      batch_size)\n",
    "    \n",
    "    train_output, infer_output = decoding_layer(dec_input,\n",
    "                                               enc_states, \n",
    "                                               target_sequence_length, \n",
    "                                               max_target_sentence_length,\n",
    "                                               rnn_size,\n",
    "                                              num_layers,\n",
    "                                              target_vocab_to_int,\n",
    "                                              target_vocab_size,\n",
    "                                              batch_size,\n",
    "                                              keep_prob,\n",
    "                                              dec_embedding_size)\n",
    "    \n",
    "    \n",
    "    '''print(dec_input)\n",
    "    print(\"************\")\n",
    "    print(enc_states)\n",
    "    print(\"************\")'''\n",
    "    \n",
    "    return train_output, infer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_step = 30\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "rnn_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "encoding_embedding_size = 100\n",
    "decoding_embedding_size = 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_probability = 0.5\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'checkpoints/ayan'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, target_sequence_length, max_target_sequence_length = enc_dec_model_inputs()\n",
    "    lr, keep_prob = hyperparam_inputs()\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "    \n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/sequence_mask\n",
    "    # - Returns a mask tensor representing the first N positions of each cell.\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function - weighted softmax cross entropy\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        \n",
    "        \n",
    "        '''tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),max_grad_norm)'''\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and validation sets\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n",
    "                                                                                                             valid_target,\n",
    "                                                                                                             batch_size,\n",
    "                                                                                                             source_vocab_to_int['<PAD>'],\n",
    "                                                                                                             target_vocab_to_int['<PAD>']))               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   30/156 - Train Accuracy: 0.3229, Validation Accuracy: 0.4844, Loss: 4.4510\n",
      "Epoch   0 Batch   60/156 - Train Accuracy: 0.2578, Validation Accuracy: 0.4844, Loss: 4.5386\n",
      "Epoch   0 Batch   90/156 - Train Accuracy: 0.3571, Validation Accuracy: 0.4844, Loss: 3.9698\n",
      "Epoch   0 Batch  120/156 - Train Accuracy: 0.5039, Validation Accuracy: 0.5391, Loss: 3.5375\n",
      "Epoch   0 Batch  150/156 - Train Accuracy: 0.3504, Validation Accuracy: 0.5703, Loss: 4.2354\n",
      "Epoch   1 Batch   30/156 - Train Accuracy: 0.3281, Validation Accuracy: 0.5755, Loss: 3.7231\n",
      "Epoch   1 Batch   60/156 - Train Accuracy: 0.3255, Validation Accuracy: 0.5208, Loss: 3.9825\n",
      "Epoch   1 Batch   90/156 - Train Accuracy: 0.4196, Validation Accuracy: 0.5208, Loss: 3.6435\n",
      "Epoch   1 Batch  120/156 - Train Accuracy: 0.4180, Validation Accuracy: 0.5286, Loss: 3.3001\n",
      "Epoch   1 Batch  150/156 - Train Accuracy: 0.3996, Validation Accuracy: 0.5599, Loss: 4.0569\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    loss_track=[]\n",
    "    grad_track = []\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            #print(target_batch)\n",
    "            #print(epoch_i)\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "            loss_track.append(loss)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)               \n",
    "                \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a822780>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_params(params):\n",
    "    with open('params-du-en-bi.p', 'wb') as out_file:\n",
    "        pickle.dump(params, out_file)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    with open('params-du-en-bi.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/ayan\n",
      "Input\n",
      "  Word Ids:      [1069, 1197, 1643, 2]\n",
      "  English Words: ['how', 'are', 'you', '<UNK>']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [1526, 296, 1]\n",
      "  German Words: ich ist <EOS>\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    results = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in vocab_to_int:\n",
    "            results.append(vocab_to_int[word])\n",
    "        else:\n",
    "            results.append(vocab_to_int['<UNK>'])\n",
    "            \n",
    "    return results\n",
    "\n",
    "translate_sentence = 'how are you today?'\n",
    "\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  German Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

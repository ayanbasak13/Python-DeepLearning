{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "import collections\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "import sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi.', 'Hallo!'], ['Hi.', 'Grüß Gott!']]\n",
      "['Hi.\\tHallo!', 'Hi.\\tGrüß Gott!']\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "all_lines=[]\n",
    "\n",
    "fptr = open('deu.txt', 'r', encoding='utf-8')\n",
    "# read all text\n",
    "lines = fptr.readlines()\n",
    "#print(lines)\n",
    "for line in lines :\n",
    "    #print(line)\n",
    "    line=line.strip()\n",
    "    k = line.split('\\t')\n",
    "    \n",
    "    all_lines.append(line)\n",
    "    pairs.append(k)\n",
    "print(pairs[0:2])\n",
    "print(all_lines[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "cleaned = list()\n",
    "# prepare regex for char filtering\n",
    "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "# prepare translation table for removing punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for pair in pairs:\n",
    "    #print(pair[0])\n",
    "    \n",
    "        \n",
    "    clean_pair = list()\n",
    "    for line in pair:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        clean_pair.append(' '.join(line))\n",
    "    cleaned.append(clean_pair)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi => hallo\n",
      "hi => gru gott\n"
     ]
    }
   ],
   "source": [
    "print(cleaned[0][0] + \" => \" + cleaned[0][1])\n",
    "print(cleaned[1][0] + \" => \" + cleaned[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 'hallo'], ['hi', 'gru gott']]\n",
      "10000\n",
      "hi\n",
      "hallo\n",
      "hi\n",
      "gru gott\n"
     ]
    }
   ],
   "source": [
    "# reduce dataset size\n",
    "n_sentences = 10000\n",
    "dataset = cleaned[:n_sentences]\n",
    "print(dataset[0:2])\n",
    "print(len(dataset))\n",
    "print(dataset[0][0])\n",
    "print(dataset[0][1])\n",
    "print(dataset[1][0])\n",
    "print(dataset[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    if(len(dataset[i][0]) > max_eng_length) :\n",
    "        max_eng_length = len(dataset[i][0])\n",
    "    if(len(dataset[i][1]) > max_ger_length) :\n",
    "        max_ger_length = len(dataset[i][1])\n",
    "        \n",
    "print(max_eng_length)\n",
    "print(max_ger_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i try\n",
      "ich probiere es\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    questions.append(dataset[i][0])\n",
    "    labels.append(dataset[i][1])\n",
    "print(questions[15])\n",
    "print(labels[15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(que, lab):\n",
    "    # Preprocess\n",
    "    qs = []\n",
    "    lb = []\n",
    "\n",
    "    # to the lower case\n",
    "    for i in que :\n",
    "        i=i.lower()\n",
    "        qs.append(i)\n",
    "    for j in lab :\n",
    "        j=j.lower()\n",
    "        lb.append(j)\n",
    "\n",
    "    # create lookup tables for English and French data\n",
    "    CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "    source_vocab = []\n",
    "    target_vocab = []\n",
    "    \n",
    "    for q in qs :\n",
    "        for j in q.split() :\n",
    "            source_vocab.append(j)\n",
    "            \n",
    "    source_vocab = set(source_vocab)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for l in lb :\n",
    "        for k in l.split() :\n",
    "            target_vocab.append(k)\n",
    "            \n",
    "    target_vocab = set(target_vocab)\n",
    "    #print(target_vocab)\n",
    "    \n",
    "    source_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(source_vocab, len(CODES)):\n",
    "        source_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    source_int_to_vocab = {v_i: v for v, v_i in source_vocab_to_int.items()}    \n",
    "    \n",
    "\n",
    " \n",
    "    target_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(target_vocab, len(CODES)):\n",
    "        target_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    target_int_to_vocab = {v_i: v for v, v_i in target_vocab_to_int.items()}\n",
    "    \n",
    "    \n",
    "\n",
    "    # create list of sentences whose words are represented in index\n",
    "    \n",
    "    source_text = []\n",
    "    target_text = []\n",
    "    \n",
    "    for q in qs :\n",
    "        source_tokens = q.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        source_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(source_tokens):\n",
    "            if (token != \"\"):\n",
    "                source_token_id.append(source_vocab_to_int[token])\n",
    "\n",
    "        source_text.append(source_token_id)        \n",
    "\n",
    "    for l in lb :\n",
    "        target_tokens = l.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        target_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(target_tokens):\n",
    "            if (token != \"\"):\n",
    "                target_token_id.append(target_vocab_to_int[token])\n",
    "       \n",
    "                \n",
    "        # put <EOS> token at the end of the chosen target sentence\n",
    "        # this token suggests when to stop creating a sequence\n",
    "        target_token_id.append(target_vocab_to_int['<EOS>'])        \n",
    "        \n",
    "        target_text.append(target_token_id) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (source_text, target_text),(source_vocab_to_int, target_vocab_to_int),(source_int_to_vocab, target_int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[885], [885]]\n",
      "[[3326, 1], [595, 167, 1]]\n"
     ]
    }
   ],
   "source": [
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "\n",
    "print(source_int_text[0:2])\n",
    "print(target_int_text[0:2])\n",
    "#print(target_int_to_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_model_inputs():\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets') \n",
    "    \n",
    "    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n",
    "    max_target_len = tf.reduce_max(target_sequence_length)    \n",
    "    \n",
    "    return inputs, targets, target_sequence_length, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_inputs():\n",
    "    lr_rate = tf.placeholder(tf.float32, name='lr_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return lr_rate, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # get '<GO>' id\n",
    "    go_id = target_vocab_to_int['<GO>']\n",
    "    \n",
    "    after_slice = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    after_concat = tf.concat( [tf.fill([batch_size, 1], go_id), after_slice], 1)\n",
    "    \n",
    "    return after_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n",
    "                   source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    :return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    embed = tf.contrib.layers.embed_sequence(rnn_inputs, \n",
    "                                             vocab_size=source_vocab_size, \n",
    "                                             embed_dim=encoding_embedding_size)\n",
    "    print(embed)\n",
    "    print(\"#########\")\n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(rnn_size), keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(stacked_cells, \n",
    "                                       embed, \n",
    "                                       dtype=tf.float32)\n",
    "    print(stacked_cells)\n",
    "    print(\"#########\")\n",
    "    print(outputs)\n",
    "    print(\"#########\")\n",
    "    print(state)\n",
    "    \n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                         target_sequence_length, max_summary_length, \n",
    "                         output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a training process in decoding layer \n",
    "    :return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    # for only input layer\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, \n",
    "                                               target_sequence_length)\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "\n",
    "    # unrolling the decoder layer\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_summary_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length,\n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a inference process in decoding layer \n",
    "    :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings, \n",
    "                                                      tf.fill([batch_size], start_of_sequence_id), \n",
    "                                                      end_of_sequence_id)\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "    \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer(dec_input, encoder_state,\n",
    "                   target_sequence_length, max_target_sequence_length,\n",
    "                   rnn_size,\n",
    "                   num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    target_vocab_size = len(target_vocab_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "    \n",
    "    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        output_layer = tf.layers.Dense(target_vocab_size)\n",
    "        train_output = decoding_layer_train(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embed_input, \n",
    "                                            target_sequence_length, \n",
    "                                            max_target_sequence_length, \n",
    "                                            output_layer, \n",
    "                                            keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        infer_output = decoding_layer_infer(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embeddings, \n",
    "                                            target_vocab_to_int['<GO>'], \n",
    "                                            target_vocab_to_int['<EOS>'], \n",
    "                                            max_target_sequence_length, \n",
    "                                            target_vocab_size, \n",
    "                                            output_layer,\n",
    "                                            batch_size,\n",
    "                                            keep_prob)\n",
    "\n",
    "    return (train_output, infer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  target_sequence_length,\n",
    "                  max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence model\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    enc_outputs, enc_states = encoding_layer(input_data, \n",
    "                                             rnn_size, \n",
    "                                             num_layers, \n",
    "                                             keep_prob, \n",
    "                                             source_vocab_size, \n",
    "                                             enc_embedding_size)\n",
    "    \n",
    "    dec_input = process_decoder_input(target_data, \n",
    "                                      target_vocab_to_int, \n",
    "                                      batch_size)\n",
    "    \n",
    "    train_output, infer_output = decoding_layer(dec_input,\n",
    "                                               enc_states, \n",
    "                                               target_sequence_length, \n",
    "                                               max_target_sentence_length,\n",
    "                                               rnn_size,\n",
    "                                              num_layers,\n",
    "                                              target_vocab_to_int,\n",
    "                                              target_vocab_size,\n",
    "                                              batch_size,\n",
    "                                              keep_prob,\n",
    "                                              dec_embedding_size)\n",
    "    \n",
    "    return train_output, infer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_step = 30\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "rnn_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "encoding_embedding_size = 100\n",
    "decoding_embedding_size = 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_probability = 0.5\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"EmbedSequence/embedding_lookup:0\", shape=(?, ?, 100), dtype=float32)\n",
      "#########\n",
      "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000000001CC08CF8>\n",
      "#########\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(?, ?, 128), dtype=float32)\n",
      "#########\n",
      "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_6:0' shape=(?, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_7:0' shape=(?, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_8:0' shape=(?, 128) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "save_path = 'checkpoints/ayan'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, target_sequence_length, max_target_sequence_length = enc_dec_model_inputs()\n",
    "    lr, keep_prob = hyperparam_inputs()\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "    \n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/sequence_mask\n",
    "    # - Returns a mask tensor representing the first N positions of each cell.\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function - weighted softmax cross entropy\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        \n",
    "        \n",
    "        '''tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),max_grad_norm)'''\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and validation sets\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n",
    "                                                                                                             valid_target,\n",
    "                                                                                                             batch_size,\n",
    "                                                                                                             source_vocab_to_int['<PAD>'],\n",
    "                                                                                                             target_vocab_to_int['<PAD>']))               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   30/156 - Train Accuracy: 0.3229, Validation Accuracy: 0.4844, Loss: 4.4107\n",
      "Epoch   0 Batch   60/156 - Train Accuracy: 0.2578, Validation Accuracy: 0.4844, Loss: 4.7437\n",
      "Epoch   0 Batch   90/156 - Train Accuracy: 0.3103, Validation Accuracy: 0.4844, Loss: 4.1123\n",
      "Epoch   0 Batch  120/156 - Train Accuracy: 0.4160, Validation Accuracy: 0.4844, Loss: 3.6666\n",
      "Epoch   0 Batch  150/156 - Train Accuracy: 0.3504, Validation Accuracy: 0.4844, Loss: 4.3547\n",
      "Epoch   1 Batch   30/156 - Train Accuracy: 0.3281, Validation Accuracy: 0.5286, Loss: 3.8608\n",
      "Epoch   1 Batch   60/156 - Train Accuracy: 0.2734, Validation Accuracy: 0.5130, Loss: 4.2162\n",
      "Epoch   1 Batch   90/156 - Train Accuracy: 0.3192, Validation Accuracy: 0.5000, Loss: 3.7537\n",
      "Epoch   1 Batch  120/156 - Train Accuracy: 0.4531, Validation Accuracy: 0.5026, Loss: 3.4068\n",
      "Epoch   1 Batch  150/156 - Train Accuracy: 0.3527, Validation Accuracy: 0.5443, Loss: 4.1903\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #sess.graph.finalize()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    loss_track=[]\n",
    "    grad_track = []\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            #print(target_batch)\n",
    "            #print(epoch_i)\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "            loss_track.append(loss)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)               \n",
    "                \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cd2f320>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_params(params):\n",
    "    with open('params-du.p', 'wb') as out_file:\n",
    "        pickle.dump(params, out_file)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    with open('params-du.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/ayan\n",
      "Input\n",
      "  Word Ids:      [2019, 259, 590, 2]\n",
      "  English Words: ['how', 'are', 'you', '<UNK>']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [2167, 2167, 1]\n",
      "  German Words: ich ich <EOS>\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    results = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in vocab_to_int:\n",
    "            results.append(vocab_to_int[word])\n",
    "        else:\n",
    "            results.append(vocab_to_int['<UNK>'])\n",
    "            \n",
    "    return results\n",
    "\n",
    "translate_sentence = 'how are you today?'\n",
    "\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  German Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
